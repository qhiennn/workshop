[{"uri":"https://qhiennn.github.io/workshop/","title":"Backup &amp; Disaster Recovery","tags":[],"description":"","content":"Working with AWS Backup \u0026amp; Disaster Recovery Automation Overview In this lab, you will learn the basic concepts and practice using AWS Backup and Disaster Recovery for a multi-database environment (DynamoDB, DocumentDB,\u0026hellip;).\nThe lab covers creating an automated backup plan, securely storing backup copies, testing data restoration capability, and setting up notifications for incidents.\nContents  Project Introduction Prerequisites Create and Configure Backup Plan Integrate Lambda Functions for Verification \u0026amp; Notifications Resource Cleanup  "},{"uri":"https://qhiennn.github.io/workshop/1-introduce/","title":"Introduction","tags":[],"description":"","content":"Backup and Disaster Recovery Automation for Multi-Database Environment is a solution that automates the backup and restoration processes for various types of databases on AWS, such as Amazon RDS, DynamoDB, and DocumentDB.\nThis solution ensures that data is always available, minimizes the risk of loss, and meets the requirements for RTO (Recovery Time Objective) and RPO (Recovery Point Objective).\nKey Benefits:  Automates the entire periodic backup process. Tests recovery capabilities to ensure backups are functional. Sends alerts in case of backup or restoration failures. Secures data through encryption and IAM access control. Centralized monitoring via CloudWatch and AWS Config. Scalable to support multi-region Disaster Recovery in the future.  With this approach, the system is not only suitable for real production environments but also helps save operational time and costs while ensuring data safety for the Hutech Event Ticket Booking Website. "},{"uri":"https://qhiennn.github.io/workshop/2-prerequiste/2.1-createvpc/","title":"Prepare AWS Environment","tags":[],"description":"","content":"ðŸš€ Guide to Creating an EC2 Instance on AWS 1. Log in to AWS Console  Go to https://console.aws.amazon.com/ Select EC2 from the service menu.   2. Create an EC2 Instance  Click Launch instance. Name: e.g., EC2-DynamoDB-Workshop. Select Amazon Machine Image (AMI):  Amazon Linux 2 AMI (HVM), SSD Volume Type.   Choose Instance Type:  t2.micro (Free Tier).   Create or select a Key Pair:  If you donâ€™t have one, choose Create new key pair and download the .pem file.   Configure Network:  VPC: Select the default VPC or a custom VPC. Subnet: Choose a subnet in your preferred region. Enable Auto-assign Public IP: Yes.   Security Group:  Create a new one or choose an existing Security Group with rules:  SSH (Port 22) - Your IP. (Optional) Add HTTP (Port 80) and HTTPS (Port 443) depending on your project.     Storage:  8 GiB (SSD GP2) is sufficient for the workshop.   Click Launch Instance.   3. Connect to the EC2 Instance  Go to EC2 Dashboard â†’ Select the instance you just created. Click Connect â†’ Select the SSH client tab. Run the following commands on your local machine:  chmod 400 your-key.pem ssh -i \u0026#34;your-key.pem\u0026#34; ec2-user@\u0026lt;Public-IP\u0026gt; "},{"uri":"https://qhiennn.github.io/workshop/2-prerequiste/2.2-createpublicsubnet/","title":"Create Public Subnet","tags":[],"description":"","content":"ðŸš€ Guide to Creating DynamoDB Tables on EC2 using AWS CLI 1. Install AWS CLI on EC2 (Amazon Linux 2) sudo yum update -y sudo yum install unzip -y curl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip sudo ./aws/install aws --version  2. Log in to AWS CLI aws configure Enter:\n AWS Access Key ID: (Get from IAM) AWS Secret Access Key: (Get from IAM)  Default region name: ap-southeast-1 Default output format: json   ðŸ”¹ The IAM user must have permissions for dynamodb:CreateTable, dynamodb:PutItem, dynamodb:DescribeTable, dynamodb:ListTables.\n  3. Create the create_tables.sh file nano create_tables.sh Paste the following content:\n#!/bin/bash  # ====== 1. CategoryHoiThao ====== aws dynamodb create-table --table-name CategoryHoiThao --attribute-definitions AttributeName=categoryId,AttributeType=S --key-schema AttributeName=categoryId,KeyType=HASH --billing-mode PAY_PER_REQUEST aws dynamodb put-item --table-name CategoryHoiThao --item \u0026#39;{\u0026#34;categoryId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;C001\u0026#34;}, \u0026#34;name\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;Technology Conference\u0026#34;}}\u0026#39; # ====== 2. HistoryBook ====== aws dynamodb create-table --table-name HistoryBook --attribute-definitions AttributeName=bookingId,AttributeType=S AttributeName=eventId,AttributeType=S --key-schema AttributeName=bookingId,KeyType=HASH AttributeName=eventId,KeyType=RANGE --billing-mode PAY_PER_REQUEST aws dynamodb put-item --table-name HistoryBook --item \u0026#39;{\u0026#34;bookingId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;B001\u0026#34;}, \u0026#34;eventId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;E001\u0026#34;}, \u0026#34;status\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;confirmed\u0026#34;}}\u0026#39; # ====== 3. HistoryBookUsers ====== aws dynamodb create-table --table-name HistoryBookUsers --attribute-definitions AttributeName=userId,AttributeType=S AttributeName=bookingId,AttributeType=S --key-schema AttributeName=userId,KeyType=HASH AttributeName=bookingId,KeyType=RANGE --billing-mode PAY_PER_REQUEST aws dynamodb put-item --table-name HistoryBookUsers --item \u0026#39;{\u0026#34;userId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;U001\u0026#34;}, \u0026#34;bookingId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;B001\u0026#34;}}\u0026#39; # ====== 4. HoiThao ====== aws dynamodb create-table --table-name HoiThao --attribute-definitions AttributeName=eventId,AttributeType=S --key-schema AttributeName=eventId,KeyType=HASH --billing-mode PAY_PER_REQUEST aws dynamodb put-item --table-name HoiThao --item \u0026#39;{\u0026#34;eventId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;E001\u0026#34;}, \u0026#34;title\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;AI Conference\u0026#34;}}\u0026#39; # ====== 5. Role ====== aws dynamodb create-table --table-name Role --attribute-definitions AttributeName=roleId,AttributeType=S --key-schema AttributeName=roleId,KeyType=HASH --billing-mode PAY_PER_REQUEST aws dynamodb put-item --table-name Role --item \u0026#39;{\u0026#34;roleId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;R001\u0026#34;}, \u0026#34;roleName\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;Admin\u0026#34;}}\u0026#39; # ====== 6. User ====== aws dynamodb create-table --table-name User --attribute-definitions AttributeName=userId,AttributeType=S --key-schema AttributeName=userId,KeyType=HASH --billing-mode PAY_PER_REQUEST aws dynamodb put-item --table-name User --item \u0026#39;{\u0026#34;userId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;U001\u0026#34;}, \u0026#34;userName\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;John Doe\u0026#34;}}\u0026#39; # ====== 7. UserGiaiDau ====== aws dynamodb create-table --table-name UserGiaiDau --attribute-definitions AttributeName=userId,AttributeType=S AttributeName=tournamentId,AttributeType=S --key-schema AttributeName=userId,KeyType=HASH AttributeName=tournamentId,KeyType=RANGE --billing-mode PAY_PER_REQUEST aws dynamodb put-item --table-name UserGiaiDau --item \u0026#39;{\u0026#34;userId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;U001\u0026#34;}, \u0026#34;tournamentId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;T001\u0026#34;}}\u0026#39; # ====== 8. UserHoiThao ====== aws dynamodb create-table --table-name UserHoiThao --attribute-definitions AttributeName=userId,AttributeType=S AttributeName=eventId,AttributeType=S --key-schema AttributeName=userId,KeyType=HASH AttributeName=eventId,KeyType=RANGE --billing-mode PAY_PER_REQUEST aws dynamodb put-item --table-name UserHoiThao --item \u0026#39;{\u0026#34;userId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;U001\u0026#34;}, \u0026#34;eventId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;E001\u0026#34;}}\u0026#39; # ====== 9. UserLiveShow ====== aws dynamodb create-table --table-name UserLiveShow --attribute-definitions AttributeName=userId,AttributeType=S AttributeName=liveShowId,AttributeType=S --key-schema AttributeName=userId,KeyType=HASH AttributeName=liveShowId,KeyType=RANGE --billing-mode PAY_PER_REQUEST aws dynamodb put-item --table-name UserLiveShow --item \u0026#39;{\u0026#34;userId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;U001\u0026#34;}, \u0026#34;liveShowId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;L001\u0026#34;}}\u0026#39; # ====== 10. UserRole ====== aws dynamodb create-table --table-name UserRole --attribute-definitions AttributeName=userId,AttributeType=S AttributeName=roleId,AttributeType=S --key-schema AttributeName=userId,KeyType=HASH AttributeName=roleId,KeyType=RANGE --billing-mode PAY_PER_REQUEST aws dynamodb put-item --table-name UserRole --item \u0026#39;{\u0026#34;userId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;U001\u0026#34;}, \u0026#34;roleId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;R001\u0026#34;}}\u0026#39; echo \u0026#34;âœ… All tables and sample data created successfully\u0026#34;  4. Grant execution permission \u0026amp; run the script chmod +x create_tables.sh ./create_tables.sh  5. Verify the results aws dynamodb list-tables If successful, you will see:\n{ \u0026#34;TableNames\u0026#34;: [ \u0026#34;CategoryHoiThao\u0026#34;, \u0026#34;HistoryBook\u0026#34;, \u0026#34;HistoryBookUsers\u0026#34;, \u0026#34;HoiThao\u0026#34;, \u0026#34;Role\u0026#34;, \u0026#34;User\u0026#34;, \u0026#34;UserGiaiDau\u0026#34;, \u0026#34;UserHoiThao\u0026#34;, \u0026#34;UserLiveShow\u0026#34;, \u0026#34;UserRole\u0026#34; ] }  6. Troubleshooting tips  If you encounter AccessDeniedException, check the IAM Policy of the user and ensure it has:  { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } "},{"uri":"https://qhiennn.github.io/workshop/2-prerequiste/","title":"Prerequisite Steps","tags":[],"description":"","content":"Contents  Project Introduction Prerequisite Steps Create and Configure Backup Plan Integrate Lambda Functions for Testing \u0026amp; Notifications Resource Cleanup  "},{"uri":"https://qhiennn.github.io/workshop/3-accessibilitytoinstances/","title":"Create Connection to EC2 Instance","tags":[],"description":"","content":"1. Create a connection to the EC2 instance  AWS account with permissions:  AWSBackupFullAccess AmazonDynamoDBFullAccess AWS KMS permissions if you want to enable backup encryption.   Logged in to AWS Management Console.   2. Access AWS Backup service  Open AWS Console, search for AWS Backup in the search bar. Click to open the service interface.\n   3. Create a Backup Vault  Go to Backup vaults â†’ Create backup vault. Enter:  Backup vault name: DynamoDBBackupVault Encryption key: Select AWS managed key (Default) or KMS key.   Click Create backup vault.\n   4. Create a Backup Plan  Go to Backup plans â†’ Create backup plan. Select Build a new plan. Fill in:  Backup plan name: DynamoDBDailyBackupPlan   Under Backup rule:  Rule name: DailyBackup Backup vault: select DynamoDBBackupVault Frequency: Daily Backup window: default or set your preferred backup time (e.g., 02:00 UTC) Lifecycle: Expire after 30 days   Click Create plan.\n   5. Assign DynamoDB tables to the Backup Plan  In the backup plan interface, click Assign resources. Resource type: DynamoDB Assign by: Resource ID Select all tables. IAM role: AWSBackupDefaultServiceRole  If the role doesnâ€™t exist, create it in IAM:  Service: Backup Attach permissions:  AWSBackupServiceRolePolicyForBackup AWSBackupServiceRolePolicyForRestores       Click Assign resources.\n   6. Verify Backup configuration  Go to Protected resources to check assigned tables.\n Go to Backup plans â†’ DynamoDBDailyBackupPlan to view backup schedule.\n   7. Perform a manual backup test  Go to Protected resources â†’ choose a table, e.g., CategoryHoiThao. Click Create on-demand backup. Enter:  Backup name: TestBackup_CategoryHoiThao Backup vault: DynamoDBBackupVault   Click Create on-demand backup. View results at Backup vaults â†’ DynamoDBBackupVault.\n   8. Restore data from backup (Restore Test)  Go to Backup vaults â†’ DynamoDBBackupVault. Select the backup â†’ Restore. Enter:  Target table name: CategoryHoiThao_RestoreTest   Click Restore backup. Verify in DynamoDB â†’ Tables.\n   9. Important notes  Cost: Charged based on storage size and retention time. Security: Recommended to enable KMS Encryption. Monitoring: You can set alerts via CloudWatch.  "},{"uri":"https://qhiennn.github.io/workshop/4-s3log/","title":" Deploy AWS Backup Alert &amp; Verification with Lambda and SNS","tags":[],"description":"","content":"1. Prepare SNS Topic (send Email/SMS notifications) 1.1 Create SNS Topic  Open AWS Console â†’ search SNS â†’ Topics â†’ Create topic. Select Standard. Name: BackupAlertsTopic. Click Create topic.   1.2 Create Subscription (Email/SMS)  In the SNS Topic you just created â†’ Create subscription. Protocol: Email (or SMS). Endpoint: enter your email or phone number. Click Create subscription. Confirm via email (mandatory if choosing Email).    2. Lambda Function 1 \u0026mdash; Backup Verification 2.1 Create Lambda  Go to AWS Console â†’ Lambda â†’ Create function. Author from scratch. Function name: BackupVerificationLambda. Runtime: Python 3.10.  Role: choose Create a new role with basic Lambda permissions. Click Create function.   2.2 Assign permissions to Lambda Go to IAM Console â†’ select the Lambda\u0026rsquo;s role â†’ Add inline policy â†’ JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;backup:ListBackupJobs\u0026#34;, \u0026#34;backup:DescribeBackupJob\u0026#34;, \u0026#34;dynamodb:RestoreTableFromBackup\u0026#34;, \u0026#34;rds:RestoreDBClusterFromSnapshot\u0026#34;, \u0026#34;sns:Publish\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Save as LambdaBackupPolicy. 2.3 Add environment variable  Key: SNS_TOPIC_ARN Value: ARN of the SNS Topic you just created.   2.4 Python Code  Deploy code:  import boto3 import os backup_client = boto3.client(\u0026#39;backup\u0026#39;) sns = boto3.client(\u0026#39;sns\u0026#39;) SNS_TOPIC_ARN = os.environ.get(\u0026#39;SNS_TOPIC_ARN\u0026#39;) def lambda_handler(event, context): if not SNS_TOPIC_ARN: print(\u0026#34;Error: SNS_TOPIC_ARN environment variable not configured.\u0026#34;) return try: backups = backup_client.list_backup_jobs(MaxResults=1)[\u0026#39;BackupJobs\u0026#39;] except Exception as e: print(f\u0026#34;Error fetching backup list: {e}\u0026#34;) return if not backups: print(\u0026#34;No backups found.\u0026#34;) return last_backup = backups[0] print(f\u0026#34;Checking backup: {last_backup[\u0026#39;BackupVaultName\u0026#39;]}- {last_backup[\u0026#39;State\u0026#39;]}\u0026#34;) if last_backup[\u0026#39;State\u0026#39;] != \u0026#39;COMPLETED\u0026#39;: sns.publish( TopicArn=SNS_TOPIC_ARN, Message=f\u0026#34;Backup failed: {last_backup}\u0026#34;, Subject=\u0026#34;Backup Verification Failed\u0026#34; ) else: print(\u0026#34;Backup OK.\u0026#34;)  3. Lambda Function 2 \u0026mdash; Notification Lambda 3.1 Create Lambda  Go to AWS Console â†’ Lambda â†’ Create function. Function name: BackupNotificationLambda. Runtime: Python 3.10. Role: choose Create a new role with basic Lambda permissions.   3.2 Assign SNS Publish permissions IAM Role â†’ Add inline policy:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sns:Publish\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } 3.3 Add environment variable  Key: SNS_TOPIC_ARN Value: ARN of the SNS Topic.   3.4 Python Code import boto3 import os import json sns = boto3.client(\u0026#39;sns\u0026#39;) SNS_TOPIC_ARN = os.environ.get(\u0026#39;SNS_TOPIC_ARN\u0026#39;) def lambda_handler(event, context): print(\u0026#34;Received event from AWS Backup:\u0026#34;) print(json.dumps(event, indent=2, ensure_ascii=False)) if not SNS_TOPIC_ARN: print(\u0026#34;Error: SNS_TOPIC_ARN not configured in Environment variables.\u0026#34;) return try: sns.publish( TopicArn=SNS_TOPIC_ARN, Message=f\u0026#34;Backup/Restore failed. Details: {json.dumps(event, ensure_ascii=False)}\u0026#34;, Subject=\u0026#34;AWS Backup Notification\u0026#34; ) print(\u0026#34;SNS notification sent successfully.\u0026#34;) except Exception as e: print(f\u0026#34;Error sending SNS: {e}\u0026#34;)  4. Connect Lambda with AWS Backup Events (EventBridge) 4.1 Open EventBridge  AWS Console â†’ search EventBridge â†’ Rules â†’ Create rule.  4.2 Configure Rule  Name: BackupFailEvents. Event Source: AWS events or EventBridge partner events. Event pattern:  { \u0026#34;source\u0026#34;: [\u0026#34;aws.backup\u0026#34;], \u0026#34;detail-type\u0026#34;: [\u0026#34;Backup Job State Change\u0026#34;, \u0026#34;Restore Job State Change\u0026#34;], \u0026#34;detail\u0026#34;: { \u0026#34;state\u0026#34;: [\u0026#34;FAILED\u0026#34;] } }  Target: select Lambda BackupNotificationLambda or BackupVerificationLambda.    "},{"uri":"https://qhiennn.github.io/workshop/4-s3log/4.1-testkiemtra/","title":"Test Verification","tags":[],"description":"","content":"1. Test BackupNotificationLambda using EventBridge test event  Go to Lambda function: BackupNotificationLambda Select Test â†’ Configure test event Choose Create new test event Name: testBackupFail Paste the following EventBridge-style JSON into Event JSON:   { \u0026#34;version\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;test-id-123\u0026#34;, \u0026#34;detail-type\u0026#34;: \u0026#34;Backup Job State Change\u0026#34;, \u0026#34;source\u0026#34;: \u0026#34;aws.backup\u0026#34;, \u0026#34;account\u0026#34;: \u0026#34;123456789012\u0026#34;, \u0026#34;time\u0026#34;: \u0026#34;2025-08-10T12:00:00Z\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;detail\u0026#34;: { \u0026#34;state\u0026#34;: \u0026#34;FAILED\u0026#34;, \u0026#34;backupJobId\u0026#34;: \u0026#34;test-backup-123\u0026#34;, \u0026#34;backupVaultName\u0026#34;: \u0026#34;Default\u0026#34;, \u0026#34;resourceArn\u0026#34;: \u0026#34;arn:aws:rds:ap-southeast-1:123456789012:db:mydb\u0026#34; } }  Save â†’ Test â†’ Observe the result and check your email.    2. Test BackupVerificationLambda (manual run)  Go to Lambda function: BackupVerificationLambda Select Test Create test event {} â†’ Test Check logs:  If Lambda publishes SNS â†’ You will receive an email. If there are no backup jobs â†’ You will see the log \u0026ldquo;No backup jobs found.\u0026rdquo;      3. Check CloudWatch Logs  Go to AWS Console â†’ CloudWatch â†’ Logs  Select log group:  /aws/lambda/BackupNotificationLambda  /aws/lambda/BackupVerificationLambda    Open the latest log stream Read the log to verify the results.   BackupNotificationLambda  BackupVerificationLambda   "},{"uri":"https://qhiennn.github.io/workshop/5-cleanup/","title":"Resource Cleanup","tags":[],"description":"","content":"After completing the lab, you need to delete the AWS resources created to avoid incurring unnecessary costs. This section will guide you step-by-step on how to delete the resources created during the Backup \u0026amp; Disaster Recovery workshop.\nDelete EC2 Instance  Go to the EC2 management console  Click Instances. Select EC2BackUp. Click Instance state. Click Terminate instance, then click Terminate to confirm.    Delete Backup Plan \u0026amp; Backup Vault  Go to AWS Console â†’ AWS Backup. Delete Backup Plan:  Select Backup plans. Select the plan created in the lab. Click Delete â†’ Confirm.   Delete Backup Vault (if no longer needed):  Go to Backup vaults. Select your vault (e.g., Default or custom name). Delete all Recovery Points inside the vault. Click Delete vault.    Delete DynamoDB Tables  Go to AWS Console â†’ DynamoDB â†’ Tables. Select and delete each table created:  CategoryHoiThao HistoryBook HistoryBookUsers HoiThao Role User UserGiaiDau UserHoiThao UserLiveShow UserRole   Click Delete table â†’ Confirm.  Delete DocumentDB Cluster  Go to AWS Console â†’ Amazon DocumentDB. Select the cluster. Click Actions â†’ Delete cluster. Tick the option to delete snapshots (if you donâ€™t need to keep them) â†’ Confirm.  Delete Lambda Functions  Go to AWS Console â†’ Lambda. Delete the functions:  BackupNotificationLambda BackupVerificationLambda    Delete SNS Topics \u0026amp; Subscriptions  Go to AWS Console â†’ Amazon SNS. Delete the topic used for notifications. Delete the related subscriptions.  Delete IAM Roles and Policies  Go to AWS Console â†’ IAM. Delete the roles created for Lambda and database access. Delete the custom policies created in the lab.  "},{"uri":"https://qhiennn.github.io/workshop/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://qhiennn.github.io/workshop/tags/","title":"Tags","tags":[],"description":"","content":""}]