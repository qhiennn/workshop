[{"uri":"https://qhiennn.github.io/workshop/","title":"Session Management","tags":[],"description":"","content":"Work with Amazon System Manager - Session Manager Overall In this lab, you\u0026rsquo;ll learn the basics and practice of Amazon System Manager - Session Manager . Perform creating public and private instance connections.\nContent  Introduction  Preparation Connect to EC2 instance Manage session logs Port Forwarding Clean up resources  "},{"uri":"https://qhiennn.github.io/workshop/1-introduce/","title":"Introduction","tags":[],"description":"","content":"Backup and Disaster Recovery Automation for Multi-Database Environment is a solution that automates the backup and restoration processes for various types of databases on AWS, such as Amazon RDS, DynamoDB, and DocumentDB.\nThis solution ensures that data is always available, minimizes the risk of loss, and meets the requirements for RTO (Recovery Time Objective) and RPO (Recovery Point Objective).\nKey Benefits:  Automates the entire periodic backup process. Tests recovery capabilities to ensure backups are functional. Sends alerts in case of backup or restoration failures. Secures data through encryption and IAM access control. Centralized monitoring via CloudWatch and AWS Config. Scalable to support multi-region Disaster Recovery in the future.  With this approach, the system is not only suitable for real production environments but also helps save operational time and costs while ensuring data safety for the Hutech Event Ticket Booking Website. "},{"uri":"https://qhiennn.github.io/workshop/2-prerequiste/2.1-createec2/2.1.1-createvpc/","title":"Prepare AWS Environment","tags":[],"description":"","content":"ðŸš€ Guide to Creating an EC2 Instance on AWS 1. Log in to AWS Console  Go to https://console.aws.amazon.com/ Select EC2 from the service menu.   2. Create an EC2 Instance  Click Launch instance. Name: e.g., EC2-DynamoDB-Workshop. Select Amazon Machine Image (AMI):  Amazon Linux 2 AMI (HVM), SSD Volume Type.   Choose Instance Type:  t2.micro (Free Tier).   Create or select a Key Pair:  If you donâ€™t have one, choose Create new key pair and download the .pem file.   Configure Network:  VPC: Select the default VPC or a custom VPC. Subnet: Choose a subnet in your preferred region. Enable Auto-assign Public IP: Yes.   Security Group:  Create a new one or choose an existing Security Group with rules:  SSH (Port 22) - Your IP. (Optional) Add HTTP (Port 80) and HTTPS (Port 443) depending on your project.     Storage:  8 GiB (SSD GP2) is sufficient for the workshop.   Click Launch Instance.   3. Connect to the EC2 Instance  Go to EC2 Dashboard â†’ Select the instance you just created. Click Connect â†’ Select the SSH client tab. Run the following commands on your local machine:  chmod 400 your-key.pem ssh -i \u0026#34;your-key.pem\u0026#34; ec2-user@\u0026lt;Public-IP\u0026gt; "},{"uri":"https://qhiennn.github.io/workshop/2-prerequiste/2.1-createec2/","title":"Preparing VPC and EC2","tags":[],"description":"","content":"In this step, we will need to create a VPC with 2 public / private subnets. Then create 1 EC2 Instance Linux located in the public subnet, 1 EC2 Instance Windows located in the private subnet.\nThe architecture overview after you complete this step will be as follows:\nTo learn how to create EC2 instances and VPCs with public/private subnets, you can refer to the lab:\n About Amazon EC2 Works with Amazon VPC  Content  Create VPC Create Public Subnet Create Private Subnet Create security group Create public Linux server Create private Windows server  "},{"uri":"https://qhiennn.github.io/workshop/4-s3log/4.1-testkiemtra/","title":"Test Verification","tags":[],"description":"","content":"1. Test BackupNotificationLambda using EventBridge test event   Go to Lambda function: BackupNotificationLambda\n  Select Test â†’ Configure test event\n  Choose Create new test event\n  Name: testBackupFail\n  Paste the following EventBridge-style JSON into Event JSON: json { \u0026ldquo;version\u0026rdquo;: \u0026ldquo;0\u0026rdquo;, \u0026ldquo;id\u0026rdquo;: \u0026ldquo;test-id-123\u0026rdquo;, \u0026ldquo;detail-type\u0026rdquo;: \u0026ldquo;Backup Job State Change\u0026rdquo;, \u0026ldquo;source\u0026rdquo;: \u0026ldquo;aws.backup\u0026rdquo;, \u0026ldquo;account\u0026rdquo;: \u0026ldquo;123456789012\u0026rdquo;, \u0026ldquo;time\u0026rdquo;: \u0026ldquo;2025-08-10T12:00:00Z\u0026rdquo;, \u0026ldquo;region\u0026rdquo;: \u0026ldquo;ap-southeast-1\u0026rdquo;, \u0026ldquo;detail\u0026rdquo;: { \u0026ldquo;state\u0026rdquo;: \u0026ldquo;FAILED\u0026rdquo;, \u0026ldquo;backupJobId\u0026rdquo;: \u0026ldquo;test-backup-123\u0026rdquo;, \u0026ldquo;backupVaultName\u0026rdquo;: \u0026ldquo;Default\u0026rdquo;, \u0026ldquo;resourceArn\u0026rdquo;: \u0026ldquo;arn:aws:rds:ap-southeast-1:123456789012:db:mydb\u0026rdquo; } }\n  Save â†’ Test â†’ Observe the result and check your email.    2. Test BackupVerificationLambda (manual run)  Go to Lambda function: BackupVerificationLambda Select Test Create test event {} â†’ Test Check logs:  If Lambda publishes SNS â†’ You will receive an email. If there are no backup jobs â†’ You will see the log \u0026ldquo;No backup jobs found.\u0026rdquo;      3. Check CloudWatch Logs  Go to AWS Console â†’ CloudWatch â†’ Logs  Select log group:  /aws/lambda/BackupNotificationLambda  /aws/lambda/BackupVerificationLambda    Open the latest log stream Read the log to verify the results.   BackupNotificationLambda  BackupVerificationLambda   "},{"uri":"https://qhiennn.github.io/workshop/2-prerequiste/2.1-createec2/2.1.2-createpublicsubnet/","title":"Create Public Subnet","tags":[],"description":"","content":"ðŸš€ Guide to Creating DynamoDB Tables on EC2 using AWS CLI 1. Install AWS CLI on EC2 (Amazon Linux 2) sudo yum update -y sudo yum install unzip -y curl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip sudo ./aws/install aws --version  2. Log in to AWS CLI aws configure Enter:\n AWS Access Key ID: (Get from IAM) AWS Secret Access Key: (Get from IAM)  Default region name: ap-southeast-1 Default output format: json   ðŸ”¹ The IAM user must have permissions for dynamodb:CreateTable, dynamodb:PutItem, dynamodb:DescribeTable, dynamodb:ListTables.\n  3. Create the create_tables.sh file nano create_tables.sh Paste the following content:\n#!/bin/bash  # ====== 1. CategoryHoiThao ====== aws dynamodb create-table --table-name CategoryHoiThao --attribute-definitions AttributeName=categoryId,AttributeType=S --key-schema AttributeName=categoryId,KeyType=HASH --billing-mode PAY_PER_REQUEST aws dynamodb put-item --table-name CategoryHoiThao --item \u0026#39;{\u0026#34;categoryId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;C001\u0026#34;}, \u0026#34;name\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;Technology Conference\u0026#34;}}\u0026#39; # ====== 2. HistoryBook ====== aws dynamodb create-table --table-name HistoryBook --attribute-definitions AttributeName=bookingId,AttributeType=S AttributeName=eventId,AttributeType=S --key-schema AttributeName=bookingId,KeyType=HASH AttributeName=eventId,KeyType=RANGE --billing-mode PAY_PER_REQUEST aws dynamodb put-item --table-name HistoryBook --item \u0026#39;{\u0026#34;bookingId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;B001\u0026#34;}, \u0026#34;eventId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;E001\u0026#34;}, \u0026#34;status\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;confirmed\u0026#34;}}\u0026#39; # ====== 3. HistoryBookUsers ====== aws dynamodb create-table --table-name HistoryBookUsers --attribute-definitions AttributeName=userId,AttributeType=S AttributeName=bookingId,AttributeType=S --key-schema AttributeName=userId,KeyType=HASH AttributeName=bookingId,KeyType=RANGE --billing-mode PAY_PER_REQUEST aws dynamodb put-item --table-name HistoryBookUsers --item \u0026#39;{\u0026#34;userId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;U001\u0026#34;}, \u0026#34;bookingId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;B001\u0026#34;}}\u0026#39; # ====== 4. HoiThao ====== aws dynamodb create-table --table-name HoiThao --attribute-definitions AttributeName=eventId,AttributeType=S --key-schema AttributeName=eventId,KeyType=HASH --billing-mode PAY_PER_REQUEST aws dynamodb put-item --table-name HoiThao --item \u0026#39;{\u0026#34;eventId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;E001\u0026#34;}, \u0026#34;title\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;AI Conference\u0026#34;}}\u0026#39; # ====== 5. Role ====== aws dynamodb create-table --table-name Role --attribute-definitions AttributeName=roleId,AttributeType=S --key-schema AttributeName=roleId,KeyType=HASH --billing-mode PAY_PER_REQUEST aws dynamodb put-item --table-name Role --item \u0026#39;{\u0026#34;roleId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;R001\u0026#34;}, \u0026#34;roleName\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;Admin\u0026#34;}}\u0026#39; # ====== 6. User ====== aws dynamodb create-table --table-name User --attribute-definitions AttributeName=userId,AttributeType=S --key-schema AttributeName=userId,KeyType=HASH --billing-mode PAY_PER_REQUEST aws dynamodb put-item --table-name User --item \u0026#39;{\u0026#34;userId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;U001\u0026#34;}, \u0026#34;userName\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;John Doe\u0026#34;}}\u0026#39; # ====== 7. UserGiaiDau ====== aws dynamodb create-table --table-name UserGiaiDau --attribute-definitions AttributeName=userId,AttributeType=S AttributeName=tournamentId,AttributeType=S --key-schema AttributeName=userId,KeyType=HASH AttributeName=tournamentId,KeyType=RANGE --billing-mode PAY_PER_REQUEST aws dynamodb put-item --table-name UserGiaiDau --item \u0026#39;{\u0026#34;userId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;U001\u0026#34;}, \u0026#34;tournamentId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;T001\u0026#34;}}\u0026#39; # ====== 8. UserHoiThao ====== aws dynamodb create-table --table-name UserHoiThao --attribute-definitions AttributeName=userId,AttributeType=S AttributeName=eventId,AttributeType=S --key-schema AttributeName=userId,KeyType=HASH AttributeName=eventId,KeyType=RANGE --billing-mode PAY_PER_REQUEST aws dynamodb put-item --table-name UserHoiThao --item \u0026#39;{\u0026#34;userId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;U001\u0026#34;}, \u0026#34;eventId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;E001\u0026#34;}}\u0026#39; # ====== 9. UserLiveShow ====== aws dynamodb create-table --table-name UserLiveShow --attribute-definitions AttributeName=userId,AttributeType=S AttributeName=liveShowId,AttributeType=S --key-schema AttributeName=userId,KeyType=HASH AttributeName=liveShowId,KeyType=RANGE --billing-mode PAY_PER_REQUEST aws dynamodb put-item --table-name UserLiveShow --item \u0026#39;{\u0026#34;userId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;U001\u0026#34;}, \u0026#34;liveShowId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;L001\u0026#34;}}\u0026#39; # ====== 10. UserRole ====== aws dynamodb create-table --table-name UserRole --attribute-definitions AttributeName=userId,AttributeType=S AttributeName=roleId,AttributeType=S --key-schema AttributeName=userId,KeyType=HASH AttributeName=roleId,KeyType=RANGE --billing-mode PAY_PER_REQUEST aws dynamodb put-item --table-name UserRole --item \u0026#39;{\u0026#34;userId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;U001\u0026#34;}, \u0026#34;roleId\u0026#34;: {\u0026#34;S\u0026#34;: \u0026#34;R001\u0026#34;}}\u0026#39; echo \u0026#34;âœ… All tables and sample data created successfully\u0026#34;  4. Grant execution permission \u0026amp; run the script chmod +x create_tables.sh ./create_tables.sh  5. Verify the results aws dynamodb list-tables If successful, you will see:\n{ \u0026#34;TableNames\u0026#34;: [ \u0026#34;CategoryHoiThao\u0026#34;, \u0026#34;HistoryBook\u0026#34;, \u0026#34;HistoryBookUsers\u0026#34;, \u0026#34;HoiThao\u0026#34;, \u0026#34;Role\u0026#34;, \u0026#34;User\u0026#34;, \u0026#34;UserGiaiDau\u0026#34;, \u0026#34;UserHoiThao\u0026#34;, \u0026#34;UserLiveShow\u0026#34;, \u0026#34;UserRole\u0026#34; ] }  6. Troubleshooting tips  If you encounter AccessDeniedException, check the IAM Policy of the user and ensure it has:  { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb:*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } "},{"uri":"https://qhiennn.github.io/workshop/2-prerequiste/","title":"Preparation ","tags":[],"description":"","content":"\rYou need to create 1 Linux instance on the public subnet and 1 Window instance on the private subnet to perform this lab.\n\rTo learn how to create EC2 instances and VPCs with public/private subnets, you can refer to the lab:\n About Amazon EC2 Works with Amazon VPC  In order to use System Manager to manage our window instances in particular and our instances in general on AWS, we need to give permission to our instances to be able to work with System Manager. In this preparation, we will also proceed to create an IAM Role to grant permissions to instances that can work with System Manager.\nContent  Prepare VPC and EC2 Create IAM Role  "},{"uri":"https://qhiennn.github.io/workshop/3-accessibilitytoinstances/","title":"Create Connection to EC2 Instance","tags":[],"description":"","content":"1. Create a connection to the EC2 instance  AWS account with permissions:  AWSBackupFullAccess AmazonDynamoDBFullAccess AWS KMS permissions if you want to enable backup encryption.   Logged in to AWS Management Console.   2. Access AWS Backup service  Open AWS Console, search for AWS Backup in the search bar. Click to open the service interface.\n   3. Create a Backup Vault  Go to Backup vaults â†’ Create backup vault. Enter:  Backup vault name: DynamoDBBackupVault Encryption key: Select AWS managed key (Default) or KMS key.   Click Create backup vault.\n   4. Create a Backup Plan  Go to Backup plans â†’ Create backup plan. Select Build a new plan. Fill in:  Backup plan name: DynamoDBDailyBackupPlan   Under Backup rule:  Rule name: DailyBackup Backup vault: select DynamoDBBackupVault Frequency: Daily Backup window: default or set your preferred backup time (e.g., 02:00 UTC) Lifecycle: Expire after 30 days   Click Create plan.\n   5. Assign DynamoDB tables to the Backup Plan  In the backup plan interface, click Assign resources. Resource type: DynamoDB Assign by: Resource ID Select all tables. IAM role: AWSBackupDefaultServiceRole  If the role doesnâ€™t exist, create it in IAM:  Service: Backup Attach permissions:  AWSBackupServiceRolePolicyForBackup AWSBackupServiceRolePolicyForRestores       Click Assign resources.\n   6. Verify Backup configuration  Go to Protected resources to check assigned tables.\n Go to Backup plans â†’ DynamoDBDailyBackupPlan to view backup schedule.\n   7. Perform a manual backup test  Go to Protected resources â†’ choose a table, e.g., CategoryHoiThao. Click Create on-demand backup. Enter:  Backup name: TestBackup_CategoryHoiThao Backup vault: DynamoDBBackupVault   Click Create on-demand backup. View results at Backup vaults â†’ DynamoDBBackupVault.\n   8. Restore data from backup (Restore Test)  Go to Backup vaults â†’ DynamoDBBackupVault. Select the backup â†’ Restore. Enter:  Target table name: CategoryHoiThao_RestoreTest   Click Restore backup. Verify in DynamoDB â†’ Tables.\n   9. Important notes  Cost: Charged based on storage size and retention time. Security: Recommended to enable KMS Encryption. Monitoring: You can set alerts via CloudWatch.  "},{"uri":"https://qhiennn.github.io/workshop/4-s3log/","title":"ðŸš€ Deploy AWS Backup Alert &amp; Verification with Lambda and SNS","tags":[],"description":"","content":"1. Prepare SNS Topic (send Email/SMS notifications) 1.1 Create SNS Topic  Open AWS Console â†’ search SNS â†’ Topics â†’ Create topic. Select Standard. Name: BackupAlertsTopic. Click Create topic.   1.2 Create Subscription (Email/SMS)  In the SNS Topic you just created â†’ Create subscription. Protocol: Email (or SMS). Endpoint: enter your email or phone number. Click Create subscription. Confirm via email (mandatory if choosing Email).    2. Lambda Function 1 \u0026mdash; Backup Verification 2.1 Create Lambda  Go to AWS Console â†’ Lambda â†’ Create function. Author from scratch. Function name: BackupVerificationLambda. Runtime: Python 3.10.  Role: choose Create a new role with basic Lambda permissions. Click Create function.   2.2 Assign permissions to Lambda Go to IAM Console â†’ select the Lambda\u0026rsquo;s role â†’ Add inline policy â†’ JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;backup:ListBackupJobs\u0026#34;, \u0026#34;backup:DescribeBackupJob\u0026#34;, \u0026#34;dynamodb:RestoreTableFromBackup\u0026#34;, \u0026#34;rds:RestoreDBClusterFromSnapshot\u0026#34;, \u0026#34;sns:Publish\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Save as LambdaBackupPolicy. 2.3 Add environment variable  Key: SNS_TOPIC_ARN Value: ARN of the SNS Topic you just created.   2.4 Python Code  Deploy code:  import boto3 import os backup_client = boto3.client(\u0026#39;backup\u0026#39;) sns = boto3.client(\u0026#39;sns\u0026#39;) SNS_TOPIC_ARN = os.environ.get(\u0026#39;SNS_TOPIC_ARN\u0026#39;) def lambda_handler(event, context): if not SNS_TOPIC_ARN: print(\u0026#34;Error: SNS_TOPIC_ARN environment variable not configured.\u0026#34;) return try: backups = backup_client.list_backup_jobs(MaxResults=1)[\u0026#39;BackupJobs\u0026#39;] except Exception as e: print(f\u0026#34;Error fetching backup list: {e}\u0026#34;) return if not backups: print(\u0026#34;No backups found.\u0026#34;) return last_backup = backups[0] print(f\u0026#34;Checking backup: {last_backup[\u0026#39;BackupVaultName\u0026#39;]}- {last_backup[\u0026#39;State\u0026#39;]}\u0026#34;) if last_backup[\u0026#39;State\u0026#39;] != \u0026#39;COMPLETED\u0026#39;: sns.publish( TopicArn=SNS_TOPIC_ARN, Message=f\u0026#34;Backup failed: {last_backup}\u0026#34;, Subject=\u0026#34;Backup Verification Failed\u0026#34; ) else: print(\u0026#34;Backup OK.\u0026#34;)  3. Lambda Function 2 \u0026mdash; Notification Lambda 3.1 Create Lambda  Go to AWS Console â†’ Lambda â†’ Create function. Function name: BackupNotificationLambda. Runtime: Python 3.10. Role: choose Create a new role with basic Lambda permissions.   3.2 Assign SNS Publish permissions IAM Role â†’ Add inline policy:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sns:Publish\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } 3.3 Add environment variable  Key: SNS_TOPIC_ARN Value: ARN of the SNS Topic.   3.4 Python Code import boto3 import os import json sns = boto3.client(\u0026#39;sns\u0026#39;) SNS_TOPIC_ARN = os.environ.get(\u0026#39;SNS_TOPIC_ARN\u0026#39;) def lambda_handler(event, context): print(\u0026#34;Received event from AWS Backup:\u0026#34;) print(json.dumps(event, indent=2, ensure_ascii=False)) if not SNS_TOPIC_ARN: print(\u0026#34;Error: SNS_TOPIC_ARN not configured in Environment variables.\u0026#34;) return try: sns.publish( TopicArn=SNS_TOPIC_ARN, Message=f\u0026#34;Backup/Restore failed. Details: {json.dumps(event, ensure_ascii=False)}\u0026#34;, Subject=\u0026#34;AWS Backup Notification\u0026#34; ) print(\u0026#34;SNS notification sent successfully.\u0026#34;) except Exception as e: print(f\u0026#34;Error sending SNS: {e}\u0026#34;)  4. Connect Lambda with AWS Backup Events (EventBridge) 4.1 Open EventBridge  AWS Console â†’ search EventBridge â†’ Rules â†’ Create rule.  4.2 Configure Rule  Name: BackupFailEvents. Event Source: AWS events or EventBridge partner events. Event pattern:  { \u0026#34;source\u0026#34;: [\u0026#34;aws.backup\u0026#34;], \u0026#34;detail-type\u0026#34;: [\u0026#34;Backup Job State Change\u0026#34;, \u0026#34;Restore Job State Change\u0026#34;], \u0026#34;detail\u0026#34;: { \u0026#34;state\u0026#34;: [\u0026#34;FAILED\u0026#34;] } }  Target: select Lambda BackupNotificationLambda or BackupVerificationLambda.    "},{"uri":"https://qhiennn.github.io/workshop/6-cleanup/","title":"Clean up resources","tags":[],"description":"","content":"We will take the following steps to delete the resources we created in this exercise.\nDelete EC2 instance   Go to EC2 service management console\n Click Instances. Select both Public Linux Instance and Private Windows Instance instances. Click Instance state. Click Terminate instance, then click Terminate to confirm.    Go to IAM service management console\n Click Roles. In the search box, enter SSM. Click to select SSM-Role. Click Delete, then enter the role name SSM-Role and click Delete to delete the role.    Click Users.  Click on user Portfwd. Click Delete, then enter the user name Portfwd and click Delete to delete the user.    Delete S3 bucket   Access System Manager - Session Manager service management console.\n Click the Preferences tab. Click Edit. Scroll down. In the section S3 logging. Uncheck Enable to disable logging. Scroll down. Click Save.    Go to S3 service management console\n Click on the S3 bucket we created for this lab. (Example: lab-fcj-bucket-0001 ) Click Empty. Enter permanently delete, then click Empty to proceed to delete the object in the bucket. Click Exit.    After deleting all objects in the bucket, click Delete\n  Enter the name of the S3 bucket, then click Delete bucket to proceed with deleting the S3 bucket.  Delete VPC Endpoints  Go to VPC service management console  Click Endpoints. Select the 4 endpoints we created for the lab including SSM, SSMMESSAGES, EC2MESSAGES, S3GW. Click Actions. Click Delete VPC endpoints.     In the confirm box, enter delete.\n Click Delete to proceed with deleting endpoints.    Click the refresh icon, check that all endpoints have been deleted before proceeding to the next step.\n  Delete VPC   Go to VPC service management console\n Click Your VPCs. Click on Lab VPC. Click Actions. Click Delete VPC.    In the confirm box, enter delete to confirm, click Delete to delete Lab VPC and related resources.\n  "},{"uri":"https://qhiennn.github.io/workshop/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://qhiennn.github.io/workshop/tags/","title":"Tags","tags":[],"description":"","content":""}]